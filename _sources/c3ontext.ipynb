{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac9d21e",
   "metadata": {},
   "source": [
    "# How to put your measurements into the meso-scale context of cloud patterns\n",
    "\n",
    "The meso-scale patterns of shallow convection as described by {cite:t}`Stevens:2021`\n",
    "are a great way to learn more about the meso-scale variability in cloudiness in the\n",
    "trades. Four meso-scale cloud patterns have been identified to frequently reoccur.\n",
    "These four patterns that are shown in the figure below are named based on their\n",
    "visual impressions: Sugar, Gravel, Flowers and Fish.\n",
    "\n",
    "```{figure} c3ontext_cloud_patterns.jpg\n",
    ":alt: Meso-scale cloud patterns\n",
    ":width: 400px\n",
    ":align: center\n",
    "\n",
    "Four meso-scale cloud patterns have been identified to be reoccuring in the trades. They are\n",
    "named based on their visual impressions: Sugar, Gravel, Flowers, Fish. Satellite image source: NASA Worldview.\n",
    "```\n",
    "\n",
    "Both rule-based algorithms and deep neural networks have been developed to identify these\n",
    "patterns automatically to learn more about their characteristics and processes.\n",
    "For the time period of the EUREC<sup>4</sup>A campaign, a group of 50 participants\n",
    "has identified these meso-scale patterns manually on satellite images. Their classifications build\n",
    "the *Common Consensus on Convective OrgaNizaTionduring the EUREC‚Å¥A eXperimenT* dataset, short\n",
    "**C<sup>3</sup>ONTEXT**.\n",
    "\n",
    "As the acronym already suggests, the dataset is meant to provide the meso-scale *context* to additional\n",
    "observations. The following example shows how this meso-scale context, the information about the most\n",
    "dominant cloud patterns, can be retrieved along a platform track. In this particular example, it is\n",
    "the track of the R/V Meteor. The measurements made onboard the research vessel like cloud radar and Raman\n",
    "lidar can therefor be analysed and interpreted with respect to the four cloud patterns.\n",
    "\n",
    "More details on this dataset can be found in {cite:t}`Schulz:2022` and\n",
    "in the [C<sup>3</sup>ONTEXT GitHub-repository](https://github.com/observingClouds/EUREC4A_manualclassifications).\n",
    "\n",
    "## Accessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09664312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import eurec4a\n",
    "from matplotlib import dates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import pathlib\n",
    "plt.style.use([pathlib.Path(\"./mplstyle/book\"), pathlib.Path(\"./mplstyle/wide\")])\n",
    "\n",
    "cat = eurec4a.get_intake_catalog(use_ipfs=\"QmahMN2wgPauHYkkiTGoG2TpPBmj3p5FoYJAq9uE9iXT9N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb192d",
   "metadata": {},
   "source": [
    "The *C<sup>3</sup>ONTEXT* dataset consists of various processing levels. In the intake catalog the level-2 and level-3 data\n",
    "are registered, which should be sufficient for most applications. These datasets consist of spatial-temporal referenced\n",
    "classification masks for all available workflows such that queries are rather simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3ontext_cat = cat.c3ontext\n",
    "list(c3ontext_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a66281",
   "metadata": {},
   "source": [
    "````{admonition} Overview about processing levels\n",
    "\n",
    "| Level | Description |\n",
    "|:---:|---|\n",
    "| 0 | Raw dataset as CSV file. No geo-referenced data, just plain labels in pixel coordinates. Includes house-keeping files. Use this dataset for analyzing the technical aspects of labels, e.g. how long did it take a person to draw a particular label. |\n",
    "| 1 | Georeferenced dataset. Only base points of the labels are given, e.g. lat0, lon0, lat1, lon1. Use this dataset for developing your own ideas where no filled masks ( see next levels ) are needed. |\n",
    "| 2 | Like level 1, but with labels being converted to masks. This dataset is easier to query if a particular position has been classified with a particular pattern or not. |\n",
    "| 3 | This processing level contains the information on how often a pattern has been classified at a specific point in time and space for each workflow (IR, VIS, ICON). To retrieve these frequencies, the level 2 data has been resampled to individual (`instant`) and daily (`daily`) composites. The `instant` dataset can be used for studies of the diurnal cycle or for analyses where the sub-daily temporal evolution is of importance. The `daily` composite give a good overview about the daily situation. It should be noted though that in case of the `daily` composite, overlapping labels of one pattern from one particular person are only counted once towards the frequency. If one person has classified for example Flowers several times a day at the same location, it is only counted once towards the frequency to reduce the bias towards the perception of a single participant. |\n",
    "```{figure} c3ontext_process_levels.png\n",
    ":alt: Processing levels\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "````\n",
    "\n",
    "## Contextualizing your data\n",
    "\n",
    "By providing time and location of interest, the dominant patterns can be retrieved. Here, we use the manual classifications\n",
    "that have been made based on infrared images. A benefit of these classifications is that they are covering the complete\n",
    "diurnal cycle. The classifications of the visible workflow miss the night-time meso-scale variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eee11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = c3ontext_cat.level3_IR_daily.to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ff2b0",
   "metadata": {},
   "source": [
    "To get the classifications along a trajectory, we can make further use of the platform tracks indexed in the EUREC<sup>4</sup>A\n",
    "Intake catalog. In the following, we show an example based on the track of the R/V Meteor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'Meteor'\n",
    "ds_plat = cat[platform].track.to_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57b08e",
   "metadata": {},
   "source": [
    "To simplify the visualization and queries, we calculate the daily average position. Note that this is just an approximation\n",
    "and will fail when the track crosses the 0 meridian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6705de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_plat_rs = ds_plat.resample(time='1D').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03081216",
   "metadata": {},
   "source": [
    "Finally, we can load the data and plot the timeseries of classifications along the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors typical used for patterns\n",
    "color_dict = {'Fish':'#2281BB',\n",
    "              'Flowers': '#93D2E2',\n",
    "              'Gravel': '#3EAE47',\n",
    "              'Sugar': '#A1D791',\n",
    "              'Unclassified' : 'lightgrey'\n",
    "             }\n",
    "\n",
    "# Reading the actual data\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    data = ds.freq.interp(latitude=ds_plat_rs.lat, longitude=ds_plat_rs.lon).sel(date=ds_plat_rs.time)\n",
    "    data.load()\n",
    "data=data.fillna(0)*100\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8,2))\n",
    "for d, (time, tdata) in enumerate(data.groupby('time')):\n",
    "    frequency = 0\n",
    "    for p in ['Sugar', 'Gravel', 'Flowers', 'Fish', 'Unclassified']:\n",
    "        ax.bar(dates.date2num(time), float(tdata.sel(pattern=p)), label=p, bottom=frequency, color=color_dict[p])\n",
    "        hfmt = dates.DateFormatter('%d.%m')\n",
    "        ax.xaxis.set_major_locator(dates.DayLocator(interval=5))\n",
    "        ax.xaxis.set_major_formatter(hfmt)\n",
    "        frequency += tdata.sel(pattern=p)\n",
    "    if d == 0:\n",
    "        plt.legend(frameon=False, bbox_to_anchor=(1,1))\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('agreement / %')\n",
    "xlim=plt.xlim(dt.datetime(2020,1,6), dt.datetime(2020,2,23))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bde5a2",
   "metadata": {},
   "source": [
    "This figure shows how many participants agreed on a specific pattern on a given date at a given location.\n",
    "\n",
    "```{note}\n",
    "Participants could attribute a given location to different patterns, causing some overlap. This overlap\n",
    "is causing the stacked bar plots to exceed 100%.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.7.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   49,
   62,
   68,
   71,
   94,
   97,
   102,
   105,
   110,
   112,
   116,
   146
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}